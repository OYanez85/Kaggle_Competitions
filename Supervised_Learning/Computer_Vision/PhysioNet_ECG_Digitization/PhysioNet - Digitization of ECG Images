{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:27.948033Z","iopub.execute_input":"2025-11-18T18:18:27.948302Z","iopub.status.idle":"2025-11-18T18:18:36.639154Z","shell.execute_reply.started":"2025-11-18T18:18:27.948287Z","shell.execute_reply":"2025-11-18T18:18:36.638252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports, config & utilities","metadata":{}},{"cell_type":"code","source":"# CHUNK 0: Imports, configuration & utilities\n\nimport os\nimport gc\nimport math\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\n\n# ============================================================\n# Basic config\n# ============================================================\nCOMP_NAME = \"physionet-ecg-image-digitization\"\nDATA_DIR = Path(f\"/kaggle/input/{COMP_NAME}\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\n\nSEED = 42\nBATCH_SIZE = 4               # you can increase later\nNUM_WORKERS = 2              # adjust to environment\nIMG_SIZE = (768, 1024)       # H, W — just a baseline; adjust as needed\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ============================================================\n# Reproducibility\n# ============================================================\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True  # speed up on GPU\n\nset_seed(SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:36.640362Z","iopub.execute_input":"2025-11-18T18:18:36.640654Z","iopub.status.idle":"2025-11-18T18:18:40.293222Z","shell.execute_reply.started":"2025-11-18T18:18:36.640640Z","shell.execute_reply":"2025-11-18T18:18:40.292527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load train/test metadata","metadata":{}},{"cell_type":"code","source":"# CHUNK 1: Load metadata (train.csv, test.csv) and inspect\n\ntrain_meta_path = DATA_DIR / \"train.csv\"\ntest_meta_path = DATA_DIR / \"test.csv\"\n\ntrain_meta = pd.read_csv(train_meta_path)\ntest_meta  = pd.read_csv(test_meta_path)\n\nprint(\"train_meta shape:\", train_meta.shape)\nprint(train_meta.head())\n\nprint(\"\\ntest_meta shape:\", test_meta.shape)\nprint(test_meta.head())\n\n# Quick sanity checks\nprint(\"\\nUnique fs in train:\", train_meta[\"fs\"].unique()[:10])\nprint(\"Unique fs in test:\", test_meta[\"fs\"].unique()[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.293771Z","iopub.execute_input":"2025-11-18T18:18:40.294049Z","iopub.status.idle":"2025-11-18T18:18:40.326845Z","shell.execute_reply.started":"2025-11-18T18:18:40.294035Z","shell.execute_reply":"2025-11-18T18:18:40.326187Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Explore a single training example (image + time series)","metadata":{}},{"cell_type":"code","source":"# CHUNK 2: Visualize one training record (DISABLED to save memory)\n\n\"\"\"\nThis exploratory section is intentionally disabled to avoid extra RAM usage\non Kaggle. If you want to use it locally, just remove the triple quotes.\n\ndef load_train_signal(example_id: int) -> pd.DataFrame:\n    '''\n    Load 12-lead ECG time series for a given training example ID.\n    Returns a DataFrame with columns: I, II, III, aVR, aVL, aVF, V1-V6.\n    '''\n    csv_path = TRAIN_DIR / str(example_id) / f\"{example_id}.csv\"\n    df = pd.read_csv(csv_path)\n    return df\n\ndef load_train_image(example_id: int, variant: str = \"0001\") -> Image.Image:\n    '''\n    Load one of the PNG images for a training example.\n    Default variant '0001' = Original color ECG image (per competition description).\n    Other variants: 0003, 0004, 0005, 0006, 0009-0012 etc.\n    '''\n    preferred_variants = [variant, \"0006\", \"0003\", \"0004\", \"0005\", \"0009\", \"0010\", \"0011\", \"0012\", \"0001\"]\n    for v in preferred_variants:\n        img_path = TRAIN_DIR / str(example_id) / f\"{example_id}-{v}.png\"\n        if img_path.exists():\n            return Image.open(img_path).convert(\"RGB\")\n    raise FileNotFoundError(f\"No PNG files found for id={example_id}\")\n\n# Example usage for local EDA:\nexample_id = int(train_meta[\"id\"].iloc[0])\nprint(\"Example ID:\", example_id)\n\nsignal_df = load_train_signal(example_id)\nprint(\"Signal shape:\", signal_df.shape)\nprint(signal_df.head())\n\nimg = load_train_image(example_id, variant=\"0001\")\nprint(\"Image size:\", img.size)\n\nplt.figure(figsize=(10, 6))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(f\"ECG Image - id={example_id}\")\nplt.show()\n\nlead_name = \"II\"\nplt.figure(figsize=(12, 3))\nplt.plot(signal_df[lead_name].values)\nplt.title(f\"Time series for lead {lead_name} - id={example_id}\")\nplt.xlabel(\"Sample index\")\nplt.ylabel(\"mV\")\nplt.tight_layout()\nplt.show()\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.328053Z","iopub.execute_input":"2025-11-18T18:18:40.328232Z","iopub.status.idle":"2025-11-18T18:18:40.334012Z","shell.execute_reply.started":"2025-11-18T18:18:40.328218Z","shell.execute_reply":"2025-11-18T18:18:40.333149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset class for training (skeleton) ","metadata":{}},{"cell_type":"code","source":"# CHUNK 3: Train Dataset skeleton (image -> 12-lead signal), no heavy usage\n\ndef load_train_signal(example_id: int) -> pd.DataFrame:\n    \"\"\"\n    Load 12-lead ECG time series for a given training example ID.\n    Returns a DataFrame with columns: I, II, III, aVR, aVL, aVF, V1-V6.\n    \"\"\"\n    csv_path = TRAIN_DIR / str(example_id) / f\"{example_id}.csv\"\n    df = pd.read_csv(csv_path)\n    return df\n\ndef load_train_image(example_id: int, variant: str = \"0001\") -> Image.Image:\n    \"\"\"\n    Load one of the PNG images for a training example.\n    Default variant '0001' = Original color ECG image.\n    Other variants: 0003, 0004, 0005, 0006, 0009-0012 etc.\n    \"\"\"\n    preferred_variants = [variant, \"0006\", \"0003\", \"0004\", \"0005\", \"0009\", \"0010\", \"0011\", \"0012\", \"0001\"]\n    for v in preferred_variants:\n        img_path = TRAIN_DIR / str(example_id) / f\"{example_id}-{v}.png\"\n        if img_path.exists():\n            return Image.open(img_path).convert(\"RGB\")\n    raise FileNotFoundError(f\"No PNG files found for id={example_id}\")\n\nclass ECGImageTrainDataset(Dataset):\n    \"\"\"\n    Training dataset:\n      - Input: single ECG image (RGB, resized)\n      - Target: 12-lead time series as a float32 numpy array (T, 12)\n\n    NOTE: We define this, but we DO NOT instantiate it in this baseline\n    to avoid unnecessary RAM usage on Kaggle.\n    \"\"\"\n    def __init__(self, metadata: pd.DataFrame, img_variant: str = \"0001\", img_size=(768, 1024)):\n        self.meta = metadata.reset_index(drop=True)\n        self.img_variant = img_variant\n        self.img_size = img_size\n\n    def __len__(self):\n        return len(self.meta)\n\n    def _load_image(self, example_id: int) -> np.ndarray:\n        img = load_train_image(example_id, variant=self.img_variant)\n        if self.img_size is not None:\n            # PIL resize expects (width, height)\n            img = img.resize((self.img_size[1], self.img_size[0]))\n        img = np.array(img).astype(np.float32) / 255.0   # (H, W, 3)\n        img = np.transpose(img, (2, 0, 1))              # (3, H, W)\n        return img\n\n    def _load_signal(self, example_id: int) -> np.ndarray:\n        df = load_train_signal(example_id)\n        lead_order = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n        df = df[lead_order]\n        return df.values.astype(np.float32)  # (T, 12)\n\n    def __getitem__(self, idx: int):\n        row = self.meta.iloc[idx]\n        example_id = int(row[\"id\"])\n        fs = row[\"fs\"]\n        sig_len = row[\"sig_len\"]\n\n        img = self._load_image(example_id)\n        signal = self._load_signal(example_id)\n\n        img_tensor = torch.from_numpy(img)        # (3, H, W)\n        sig_tensor = torch.from_numpy(signal)     # (T, 12)\n\n        return {\n            \"id\": example_id,\n            \"fs\": fs,\n            \"sig_len\": sig_len,\n            \"image\": img_tensor,\n            \"signal\": sig_tensor,\n        }\n\n# IMPORTANT:\n# We DO NOT create a dataset or dataloader here in order to keep RAM usage low.\n# When you start training a real model, you can instantiate:\n#   train_dataset = ECGImageTrainDataset(train_meta, img_variant=\"0001\", img_size=IMG_SIZE)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.334583Z","iopub.execute_input":"2025-11-18T18:18:40.334795Z","iopub.status.idle":"2025-11-18T18:18:40.354386Z","shell.execute_reply.started":"2025-11-18T18:18:40.334777Z","shell.execute_reply":"2025-11-18T18:18:40.353546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model skeleton (2D CNN encoder)","metadata":{}},{"cell_type":"code","source":"# CHUNK 4: Simple 2D CNN encoder (skeleton for future use, no heavy usage)\n\nclass SimpleECGImageEncoder(nn.Module):\n    \"\"\"\n    A very basic convolutional encoder that maps (3, H, W) -> (C, H', W').\n    You can later pool along H' and decode along W' to reconstruct time series.\n    This is only a starting point and is NOT used in the baseline submission.\n    \"\"\"\n    def __init__(self, in_channels=3, base_channels=32):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels, base_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(base_channels),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),   # (H/2, W/2)\n\n            nn.Conv2d(base_channels, base_channels * 2, kernel_size=3, padding=1),\n            nn.BatchNorm2d(base_channels * 2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),   # (H/4, W/4)\n\n            nn.Conv2d(base_channels * 2, base_channels * 4, kernel_size=3, padding=1),\n            nn.BatchNorm2d(base_channels * 4),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),   # (H/8, W/8)\n        )\n\n    def forward(self, x):\n        # x: (B, 3, H, W)\n        feat = self.features(x)  # (B, C, H', W')\n        return feat\n\n# NOTE:\n# We do NOT instantiate or run this encoder here to keep the notebook light.\n# When you start training, you can do:\n#   encoder = SimpleECGImageEncoder().to(DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.355400Z","iopub.execute_input":"2025-11-18T18:18:40.355734Z","iopub.status.idle":"2025-11-18T18:18:40.372726Z","shell.execute_reply.started":"2025-11-18T18:18:40.355713Z","shell.execute_reply":"2025-11-18T18:18:40.372052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dummy digitizer “model” used for baseline submission","metadata":{}},{"cell_type":"code","source":"# CHUNK 5: Dummy ECG digitizer for baseline submission\n\nclass DummyDigitizerModel:\n    \"\"\"\n    Baseline model that ignores the image and outputs zeros.\n    This is ONLY to get a valid submission quickly.\n    Replace with a real trained model later.\n    \"\"\"\n    def __init__(self, constant_value: float = 0.0):\n        self.constant_value = constant_value\n\n    def predict_lead(\n        self,\n        image: Image.Image,\n        lead: str,\n        fs: int,\n        n_rows: int,\n    ) -> np.ndarray:\n        \"\"\"\n        image: PIL.Image (unused in dummy model)\n        lead: str, one of [I, II, ..., V6]\n        fs: sampling frequency\n        n_rows: number_of_rows to predict for this {base_id, lead}\n        Returns: np.ndarray of shape (n_rows,) with float32 values.\n        \"\"\"\n        return np.full(shape=(n_rows,), fill_value=self.constant_value, dtype=np.float32)\n\n# Instantiate dummy model\ndigitizer = DummyDigitizerModel(constant_value=0.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.373488Z","iopub.execute_input":"2025-11-18T18:18:40.373698Z","iopub.status.idle":"2025-11-18T18:18:40.391744Z","shell.execute_reply.started":"2025-11-18T18:18:40.373679Z","shell.execute_reply":"2025-11-18T18:18:40.391035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test-time image loader & prediction loop","metadata":{}},{"cell_type":"code","source":"# CHUNK 6 + 7: Streaming prediction loop -> direct CSV write (memory safe)\n\nimport csv\n\n# Order of leads (for reference; test_meta already has 'lead' column)\nLEADS = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n\ndef load_test_image(base_id: int) -> Image.Image:\n    \"\"\"\n    Load a single test image for a given base_id.\n    According to the competition, test/[id].png exists.\n    \"\"\"\n    img_path = TEST_DIR / f\"{base_id}.png\"\n    if not img_path.exists():\n        raise FileNotFoundError(f\"Test image not found: {img_path}\")\n    img = Image.open(img_path).convert(\"RGB\")\n    return img\n\nSUBMISSION_CSV = \"submission.csv\"\n\n# Open the CSV and stream rows directly to disk\nwith open(SUBMISSION_CSV, \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"id\", \"value\"])  # header\n\n    # Loop over test metadata rows\n    for idx, row in test_meta.iterrows():\n        base_id = row[\"id\"]\n        lead = row[\"lead\"]\n        fs = int(row[\"fs\"])\n        n_rows = int(row[\"number_of_rows\"])\n\n        # Load image for this base_id (no caching to keep RAM low)\n        img = load_test_image(base_id)\n        try:\n            # Dummy model defined in CHUNK 5\n            y_pred = digitizer.predict_lead(image=img, lead=lead, fs=fs, n_rows=n_rows)\n        finally:\n            # Explicitly close image to free resources\n            img.close()\n\n        # Sanity check\n        assert y_pred.shape[0] == n_rows\n\n        # Write each predicted point directly to the CSV\n        for row_id in range(n_rows):\n            full_id = f\"{base_id}_{row_id}_{lead}\"\n            writer.writerow([full_id, float(y_pred[row_id])])\n\n        # Light progress logging\n        if (idx + 1) % 50 == 0:\n            print(f\"Processed {idx + 1}/{len(test_meta)} rows in test_meta\")\n\nprint(f\"Saved streaming submission to {SUBMISSION_CSV}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T18:18:40.392652Z","iopub.execute_input":"2025-11-18T18:18:40.392946Z","iopub.status.idle":"2025-11-18T18:18:42.406601Z","shell.execute_reply.started":"2025-11-18T18:18:40.392923Z","shell.execute_reply":"2025-11-18T18:18:42.405971Z"}},"outputs":[],"execution_count":null}]}