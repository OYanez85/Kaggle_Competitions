{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":13750964,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:47:30.879513Z","iopub.execute_input":"2025-09-26T20:47:30.879936Z","iopub.status.idle":"2025-09-26T20:47:30.899347Z","shell.execute_reply.started":"2025-09-26T20:47:30.879909Z","shell.execute_reply":"2025-09-26T20:47:30.898198Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hull-tactical-market-prediction/train.csv\n/kaggle/input/hull-tactical-market-prediction/test.csv\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# ======================================\n# Imports & Config\n# ======================================\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport lightgbm as lgb\nfrom sklearn.linear_model import ElasticNet, Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Kaggle paths\nDATA_DIR = \"/kaggle/input/hull-tactical-market-prediction\"\n\n# Reproducibility\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# Volatility targeting constants\nBASE_WEIGHT = 1.0\nWEIGHT_MIN, WEIGHT_MAX = 0.0, 2.0\nMAX_VOL_MULTIPLIER = 1.2\n\n# Forward return column\nFRET_COL = \"forward_returns\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:47:30.901131Z","iopub.execute_input":"2025-09-26T20:47:30.901518Z","iopub.status.idle":"2025-09-26T20:47:30.922026Z","shell.execute_reply.started":"2025-09-26T20:47:30.901484Z","shell.execute_reply":"2025-09-26T20:47:30.921053Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# ======================================\n# Utility Functions\n# ======================================\ndef realized_vol(series: pd.Series):\n    \"\"\"Annualized realized volatility.\"\"\"\n    return series.std(ddof=0) * np.sqrt(252.0)\n\ndef nonlinear_mapping(preds, k, base=BASE_WEIGHT, scale=0.01):\n    \"\"\"Nonlinear mapping of predictions into allocations.\"\"\"\n    w = base + k * np.tanh(preds / scale)\n    return np.clip(w, WEIGHT_MIN, WEIGHT_MAX)\n\ndef calibrate_k(preds_oof, train_pd, base=BASE_WEIGHT, scale=0.01):\n    \"\"\"Calibrate scaling factor k for volatility targeting.\"\"\"\n    fr = train_pd[FRET_COL].values.astype(np.float64)\n    valid_mask = ~np.isnan(preds_oof)\n    preds = preds_oof[valid_mask]\n    mkt = fr[valid_mask]\n\n    mkt_vol = realized_vol(pd.Series(mkt))\n    target_vol = MAX_VOL_MULTIPLIER * mkt_vol\n\n    def strat_vol_for_k(k):\n        w = nonlinear_mapping(preds, k, base=base, scale=scale)\n        strat = w * mkt\n        return realized_vol(pd.Series(strat))\n\n    if strat_vol_for_k(0.0) > target_vol:\n        return 0.0\n\n    k_lo, k_hi = 0.0, 1.0\n    while strat_vol_for_k(k_hi) < target_vol and k_hi < 50.0:\n        k_hi *= 2.0\n\n    for _ in range(40):\n        k_mid = 0.5 * (k_lo + k_hi)\n        v = strat_vol_for_k(k_mid)\n        if v > target_vol:\n            k_hi = k_mid\n        else:\n            k_lo = k_mid\n\n    k_star = k_lo\n    print(f\"[calibrate_k] k={k_star:.6f}, Market vol={mkt_vol:.4f}, Target={target_vol:.4f}\")\n    return float(k_star)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:47:30.923048Z","iopub.execute_input":"2025-09-26T20:47:30.923338Z","iopub.status.idle":"2025-09-26T20:47:30.952036Z","shell.execute_reply.started":"2025-09-26T20:47:30.923315Z","shell.execute_reply":"2025-09-26T20:47:30.950734Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# ======================================\n# Training Preprocessing\n# ======================================\n# 1. Load training data\ntrain_path = f\"{DATA_DIR}/train.csv\"\ntrain_pd = pd.read_csv(train_path)\n\n# 2. Define base features and target\nTARGET = \"forward_returns\"\nBASE_FEATURES = [c for c in train_pd.columns if c not in [\n    \"date_id\", TARGET, \"risk_free_rate\", \"market_forward_excess_returns\"\n]]\n\n# 3. Apply feature engineering (must be defined earlier)\ntrain_pd = add_features_fast(train_pd, BASE_FEATURES)\n\n# 4. Freeze final training features for LGBM\nFINAL_FEATURES = [c for c in train_pd.columns if c not in [\n    \"date_id\", TARGET, \"risk_free_rate\", \"market_forward_excess_returns\"\n]]\n\nX = train_pd[FINAL_FEATURES].values.astype(np.float32)\ny = train_pd[TARGET].values.astype(np.float32)\n\n# 5. Preprocessing for ElasticNet (scaler + imputer + PCA)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nimputer = SimpleImputer(strategy=\"median\")\nX_imputed = imputer.fit_transform(X_scaled)\n\npca = PCA(n_components=20, random_state=RANDOM_STATE)\nX_pca = pca.fit_transform(X_imputed)\n\n# Enhanced features for ElasticNet\nX_enhanced = np.hstack([X_imputed, X_pca])\n\nprint(\"Final LGBM features:\", len(FINAL_FEATURES))\nprint(\"ElasticNet features:\", X_enhanced.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:47:30.954377Z","iopub.execute_input":"2025-09-26T20:47:30.954727Z","iopub.status.idle":"2025-09-26T20:47:32.375042Z","shell.execute_reply.started":"2025-09-26T20:47:30.954685Z","shell.execute_reply":"2025-09-26T20:47:32.372945Z"}},"outputs":[{"name":"stdout","text":"Final LGBM features: 470\nElasticNet features: 490\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"# ======================================\n# Train Models\n# ======================================\n# ---- LightGBM on FINAL_FEATURES ----\ndtrain_full = lgb.Dataset(X, label=y)\n\nparams = dict(\n    objective=\"regression\",\n    metric=\"rmse\",\n    learning_rate=0.03,\n    num_leaves=64,\n    feature_fraction=0.8,\n    bagging_fraction=0.8,\n    bagging_freq=1,\n    min_data_in_leaf=40,\n    verbose=-1,\n    seed=RANDOM_STATE,\n    force_row_wise=True,\n)\n\nfinal_lgbm = lgb.train(params, dtrain_full, num_boost_round=800)\n\n# ---- ElasticNet on PCA-enhanced ----\nfinal_enet = ElasticNet(\n    alpha=0.001, l1_ratio=0.2, max_iter=200000, random_state=RANDOM_STATE\n)\nfinal_enet.fit(X_enhanced, y)\n\n# ---- Meta-model Ridge ----\npred_lgb_train = final_lgbm.predict(X)\npred_enet_train = final_enet.predict(X_enhanced)\n\nmeta_input = np.vstack([pred_lgb_train, pred_enet_train]).T\nfinal_meta = Ridge(alpha=1.0).fit(meta_input, y)\n\n# ---- Out-of-fold preds for calibration ----\noof_preds = 0.5 * pred_lgb_train + 0.5 * pred_enet_train\nK_CAL = calibrate_k(oof_preds, train_pd, scale=0.01)\n\nprint(\"✅ Models trained: LGBM + ElasticNet + Ridge meta\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T20:47:32.375823Z","iopub.execute_input":"2025-09-26T20:47:32.376145Z"}},"outputs":[{"name":"stdout","text":"[calibrate_k] k=1.198979, Market vol=0.1675, Target=0.2010\n✅ Models trained: LGBM + ElasticNet + Ridge meta\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ======================================\n# Prediction Helpers\n# ======================================\n# ======================================\n# Prediction Helpers\n# ======================================\ndef _prepare_row_array(row: pd.Series, features, scaler, imputer=None, pca=None):\n    \"\"\"Prepare one row for ElasticNet/PCA pipeline.\"\"\"\n    # Always pull only the training features\n    x = np.array([row.get(f, 0.0) for f in features], dtype=np.float32).reshape(1, -1)\n\n    # Impute missing values\n    if imputer is not None:\n        x = imputer.transform(x)\n\n    # Scale\n    x_scaled = scaler.transform(x).astype(np.float32)\n\n    # Optionally add PCA features for ElasticNet\n    if pca is not None:\n        x_pca = pca.transform(x_scaled)\n        x = np.hstack([x_scaled, x_pca])\n    else:\n        x = x_scaled\n\n    # Guard against NaN / inf\n    return np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n\n\ndef make_predict_fn(lgbm_model, enet_model, meta_model,\n                    scaler, imputer, pca,\n                    features, k_cal, base_weight, scale=0.01):\n    \"\"\"Make prediction function for row-level inference.\"\"\"\n    def predict(row: pd.Series) -> float:\n        # --- LightGBM on original features ---\n        x_lgb = np.array([row.get(f, 0.0) for f in features], dtype=np.float32).reshape(1, -1)\n        pred_lgb = float(\n            lgbm_model.predict(\n                x_lgb,\n                num_iteration=getattr(lgbm_model, \"best_iteration\", None),\n                predict_disable_shape_check=True  # ✅ avoids feature mismatch errors\n            )[0]\n        )\n\n        # --- ElasticNet on PCA-enhanced features ---\n        x_enet = _prepare_row_array(row, features, scaler, imputer, pca)\n        pred_enet = float(enet_model.predict(x_enet)[0])\n\n        # --- Meta-model blend ---\n        meta_input = np.array([[pred_lgb, pred_enet]], dtype=np.float32)\n        pred_meta = float(meta_model.predict(meta_input)[0])\n\n        # --- Allocation mapping ---\n        w = base_weight + k_cal * np.tanh(pred_meta / scale)\n        return float(np.clip(w, WEIGHT_MIN, WEIGHT_MAX))\n\n    return predict\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Load test set\ntest_path = f\"{DATA_DIR}/test.csv\"\ntest_pd_raw = pd.read_csv(test_path)\nprint(\"Test shape:\", test_pd_raw.shape)\n\n# 2. Generate predictions\npreds = []\nfor _, row in test_pd_raw.iterrows():\n    preds.append(predict(row))\n\n# 3. Optional smoothing (reduce variance, improve LB stability)\nalpha = 0.1  # smoothing factor\nsmoothed_preds = []\nprev = preds[0]\nfor p in preds:\n    smoothed = alpha * p + (1 - alpha) * prev\n    smoothed_preds.append(smoothed)\n    prev = smoothed\n\n# 4. Build submission\nsubmission = pd.DataFrame({\n    \"date_id\": test_pd_raw[\"date_id\"],   # ✅ use correct test key\n    \"allocation\": smoothed_preds         # or just `preds` if you skip smoothing\n})\n\n# 5. Save submission\nsub_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(sub_path, index=False)\nprint(\"✅ Submission saved:\", sub_path)\nprint(submission.head())\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}