{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-27T14:52:58.202519Z","iopub.execute_input":"2025-11-27T14:52:58.203133Z","iopub.status.idle":"2025-11-27T14:52:58.515740Z","shell.execute_reply.started":"2025-11-27T14:52:58.203108Z","shell.execute_reply":"2025-11-27T14:52:58.515088Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e11/sample_submission.csv\n/kaggle/input/playground-series-s5e11/train.csv\n/kaggle/input/playground-series-s5e11/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Imports & Basic Setup","metadata":{}},{"cell_type":"code","source":"# CHUNK 1: Imports & basic setup\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_DIR = \"/kaggle/input/playground-series-s5e11\"\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:52:58.517101Z","iopub.execute_input":"2025-11-27T14:52:58.517417Z","iopub.status.idle":"2025-11-27T14:52:59.639224Z","shell.execute_reply.started":"2025-11-27T14:52:58.517398Z","shell.execute_reply":"2025-11-27T14:52:59.638459Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load Data & Quick Peek","metadata":{}},{"cell_type":"code","source":"# CHUNK 2: Load data & quick inspection\n\ntrain_path = os.path.join(DATA_DIR, \"train.csv\")\ntest_path = os.path.join(DATA_DIR, \"test.csv\")\nsample_sub_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_sub_path)\n\nprint(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)\n\ndisplay(train.head())\ndisplay(train.describe(include=\"all\").T.head(20))\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:52:59.639991Z","iopub.execute_input":"2025-11-27T14:52:59.640319Z","iopub.status.idle":"2025-11-27T14:53:01.669757Z","shell.execute_reply.started":"2025-11-27T14:52:59.640301Z","shell.execute_reply":"2025-11-27T14:53:01.669135Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train shape: (593994, 13)\nTest shape: (254569, 12)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n0   0       29367.99                 0.084           736      2528.42   \n1   1       22108.02                 0.166           636      4593.10   \n2   2       49566.20                 0.097           694     17005.15   \n3   3       46858.25                 0.065           533      4682.48   \n4   4       25496.70                 0.053           665     12184.43   \n\n   interest_rate  gender marital_status education_level employment_status  \\\n0          13.67  Female         Single     High School     Self-employed   \n1          12.92    Male        Married        Master's          Employed   \n2           9.76    Male         Single     High School          Employed   \n3          16.10  Female         Single     High School          Employed   \n4          10.21    Male        Married     High School          Employed   \n\n         loan_purpose grade_subgrade  loan_paid_back  \n0               Other             C3             1.0  \n1  Debt consolidation             D3             0.0  \n2  Debt consolidation             C5             1.0  \n3  Debt consolidation             F1             1.0  \n4               Other             D1             1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>annual_income</th>\n      <th>debt_to_income_ratio</th>\n      <th>credit_score</th>\n      <th>loan_amount</th>\n      <th>interest_rate</th>\n      <th>gender</th>\n      <th>marital_status</th>\n      <th>education_level</th>\n      <th>employment_status</th>\n      <th>loan_purpose</th>\n      <th>grade_subgrade</th>\n      <th>loan_paid_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>29367.99</td>\n      <td>0.084</td>\n      <td>736</td>\n      <td>2528.42</td>\n      <td>13.67</td>\n      <td>Female</td>\n      <td>Single</td>\n      <td>High School</td>\n      <td>Self-employed</td>\n      <td>Other</td>\n      <td>C3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>22108.02</td>\n      <td>0.166</td>\n      <td>636</td>\n      <td>4593.10</td>\n      <td>12.92</td>\n      <td>Male</td>\n      <td>Married</td>\n      <td>Master's</td>\n      <td>Employed</td>\n      <td>Debt consolidation</td>\n      <td>D3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>49566.20</td>\n      <td>0.097</td>\n      <td>694</td>\n      <td>17005.15</td>\n      <td>9.76</td>\n      <td>Male</td>\n      <td>Single</td>\n      <td>High School</td>\n      <td>Employed</td>\n      <td>Debt consolidation</td>\n      <td>C5</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>46858.25</td>\n      <td>0.065</td>\n      <td>533</td>\n      <td>4682.48</td>\n      <td>16.10</td>\n      <td>Female</td>\n      <td>Single</td>\n      <td>High School</td>\n      <td>Employed</td>\n      <td>Debt consolidation</td>\n      <td>F1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>25496.70</td>\n      <td>0.053</td>\n      <td>665</td>\n      <td>12184.43</td>\n      <td>10.21</td>\n      <td>Male</td>\n      <td>Married</td>\n      <td>High School</td>\n      <td>Employed</td>\n      <td>Other</td>\n      <td>D1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                         count unique                 top    freq  \\\nid                    593994.0    NaN                 NaN     NaN   \nannual_income         593994.0    NaN                 NaN     NaN   \ndebt_to_income_ratio  593994.0    NaN                 NaN     NaN   \ncredit_score          593994.0    NaN                 NaN     NaN   \nloan_amount           593994.0    NaN                 NaN     NaN   \ninterest_rate         593994.0    NaN                 NaN     NaN   \ngender                  593994      3              Female  306175   \nmarital_status          593994      4              Single  288843   \neducation_level         593994      5          Bachelor's  279606   \nemployment_status       593994      5            Employed  450645   \nloan_purpose            593994      8  Debt consolidation  324695   \ngrade_subgrade          593994     30                  C3   58695   \nloan_paid_back        593994.0    NaN                 NaN     NaN   \n\n                              mean            std      min        25%  \\\nid                        296996.5  171471.442235      0.0  148498.25   \nannual_income         48212.202976   26711.942078  6002.43    27934.4   \ndebt_to_income_ratio      0.120696       0.068573    0.011      0.072   \ncredit_score            680.916009      55.424956    395.0      646.0   \nloan_amount           15020.297629    6926.530568   500.09   10279.62   \ninterest_rate            12.356345       2.008959      3.2      10.99   \ngender                         NaN            NaN      NaN        NaN   \nmarital_status                 NaN            NaN      NaN        NaN   \neducation_level                NaN            NaN      NaN        NaN   \nemployment_status              NaN            NaN      NaN        NaN   \nloan_purpose                   NaN            NaN      NaN        NaN   \ngrade_subgrade                 NaN            NaN      NaN        NaN   \nloan_paid_back             0.79882       0.400883      0.0        1.0   \n\n                           50%        75%        max  \nid                    296996.5  445494.75   593993.0  \nannual_income         46557.68   60981.32  393381.74  \ndebt_to_income_ratio     0.096      0.156      0.627  \ncredit_score             682.0      719.0      849.0  \nloan_amount           15000.22   18858.58   48959.95  \ninterest_rate            12.37      13.68      20.99  \ngender                     NaN        NaN        NaN  \nmarital_status             NaN        NaN        NaN  \neducation_level            NaN        NaN        NaN  \nemployment_status          NaN        NaN        NaN  \nloan_purpose               NaN        NaN        NaN  \ngrade_subgrade             NaN        NaN        NaN  \nloan_paid_back             1.0        1.0        1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>296996.5</td>\n      <td>171471.442235</td>\n      <td>0.0</td>\n      <td>148498.25</td>\n      <td>296996.5</td>\n      <td>445494.75</td>\n      <td>593993.0</td>\n    </tr>\n    <tr>\n      <th>annual_income</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48212.202976</td>\n      <td>26711.942078</td>\n      <td>6002.43</td>\n      <td>27934.4</td>\n      <td>46557.68</td>\n      <td>60981.32</td>\n      <td>393381.74</td>\n    </tr>\n    <tr>\n      <th>debt_to_income_ratio</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.120696</td>\n      <td>0.068573</td>\n      <td>0.011</td>\n      <td>0.072</td>\n      <td>0.096</td>\n      <td>0.156</td>\n      <td>0.627</td>\n    </tr>\n    <tr>\n      <th>credit_score</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>680.916009</td>\n      <td>55.424956</td>\n      <td>395.0</td>\n      <td>646.0</td>\n      <td>682.0</td>\n      <td>719.0</td>\n      <td>849.0</td>\n    </tr>\n    <tr>\n      <th>loan_amount</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15020.297629</td>\n      <td>6926.530568</td>\n      <td>500.09</td>\n      <td>10279.62</td>\n      <td>15000.22</td>\n      <td>18858.58</td>\n      <td>48959.95</td>\n    </tr>\n    <tr>\n      <th>interest_rate</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.356345</td>\n      <td>2.008959</td>\n      <td>3.2</td>\n      <td>10.99</td>\n      <td>12.37</td>\n      <td>13.68</td>\n      <td>20.99</td>\n    </tr>\n    <tr>\n      <th>gender</th>\n      <td>593994</td>\n      <td>3</td>\n      <td>Female</td>\n      <td>306175</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>marital_status</th>\n      <td>593994</td>\n      <td>4</td>\n      <td>Single</td>\n      <td>288843</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>education_level</th>\n      <td>593994</td>\n      <td>5</td>\n      <td>Bachelor's</td>\n      <td>279606</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>employment_status</th>\n      <td>593994</td>\n      <td>5</td>\n      <td>Employed</td>\n      <td>450645</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>loan_purpose</th>\n      <td>593994</td>\n      <td>8</td>\n      <td>Debt consolidation</td>\n      <td>324695</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grade_subgrade</th>\n      <td>593994</td>\n      <td>30</td>\n      <td>C3</td>\n      <td>58695</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>loan_paid_back</th>\n      <td>593994.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.79882</td>\n      <td>0.400883</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Define Features & Target, Identify Column Types","metadata":{}},{"cell_type":"code","source":"# CHUNK 3: Features / target split & column types\n\nTARGET_COL = \"loan_paid_back\"\nID_COL = \"id\"\n\n# Separate target and features\nX = train.drop(columns=[TARGET_COL])\ny = train[TARGET_COL]\n\n# Save test features (test has no target)\nX_test = test.copy()\n\n# Identify numeric & categorical columns automatically\nnumeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n\n# (Optional) Remove ID from features if present\nif ID_COL in numeric_features:\n    numeric_features.remove(ID_COL)\n\nprint(\"Numeric features:\", numeric_features)\nprint(\"Categorical features:\", categorical_features)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:53:01.670555Z","iopub.execute_input":"2025-11-27T14:53:01.670850Z","iopub.status.idle":"2025-11-27T14:53:01.753492Z","shell.execute_reply.started":"2025-11-27T14:53:01.670821Z","shell.execute_reply":"2025-11-27T14:53:01.752836Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Numeric features: ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']\nCategorical features: ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# CHUNK 3B: Feature Engineering\n\n# Create polynomial features and interactions for numeric features\nX_engineered = X.copy()\nX_test_engineered = X_test.copy()\n\n# Add polynomial features for important numeric columns\nif len(numeric_features) > 0:\n    from itertools import combinations\n    \n    # Create interaction features between numeric columns\n    for col1, col2 in combinations(numeric_features[:5], 2):  # Top 5 numeric features\n        X_engineered[f'{col1}_x_{col2}'] = X_engineered[col1] * X_engineered[col2]\n        X_test_engineered[f'{col1}_x_{col2}'] = X_test_engineered[col1] * X_test_engineered[col2]\n    \n    # Add squared features for numeric columns\n    for col in numeric_features[:5]:\n        X_engineered[f'{col}_squared'] = X_engineered[col] ** 2\n        X_test_engineered[f'{col}_squared'] = X_test_engineered[col] ** 2\n    \n    # Add log-transformed features (handle negative values)\n    for col in numeric_features[:3]:\n        if (X_engineered[col] > 0).all():\n            X_engineered[f'{col}_log'] = np.log1p(X_engineered[col])\n            X_test_engineered[f'{col}_log'] = np.log1p(X_test_engineered[col])\n\n# Update X and X_test to use engineered features\nX = X_engineered\nX_test = X_test_engineered\n\n# Recompute numeric and categorical features\nnumeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n\nif ID_COL in numeric_features:\n    numeric_features.remove(ID_COL)\n\nprint(\"After engineering:\")\nprint(\"Numeric features count:\", len(numeric_features))\nprint(\"Categorical features count:\", len(categorical_features))\nprint(\"Total features:\", len(X.columns))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T14:53:01.755285Z","iopub.execute_input":"2025-11-27T14:53:01.755481Z","iopub.status.idle":"2025-11-27T14:53:02.069757Z","shell.execute_reply.started":"2025-11-27T14:53:01.755466Z","shell.execute_reply":"2025-11-27T14:53:02.069128Z"}},"outputs":[{"name":"stdout","text":"After engineering:\nNumeric features count: 23\nCategorical features count: 6\nTotal features: 30\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Preprocessing & Model Pipeline","metadata":{}},{"cell_type":"code","source":"# CHUNK 4: Preprocessing & HistGradientBoosting model with tuning\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nnumeric_transformer = Pipeline(\n    steps=[\n        (\"scaler\", StandardScaler())\n    ]\n)\n\n# FIX: OneHotEncoder must output dense format\ncategorical_transformer = Pipeline(\n    steps=[\n        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n    ]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_features),\n        (\"cat\", categorical_transformer, categorical_features),\n    ]\n)\n\n# Improved HistGradientBoosting with better hyperparameters\nclf = HistGradientBoostingClassifier(\n    learning_rate=0.01,  # Lower learning rate for better generalization\n    max_depth=8,  # Limited depth to reduce overfitting\n    max_iter=500,  # More iterations\n    l2_regularization=0.1,  # Add L2 regularization\n    early_stopping=True,\n    validation_fraction=0.1,\n    n_iter_no_change=20,\n    random_state=RANDOM_STATE\n)\n\nmodel = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\"classifier\", clf),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:53:02.070431Z","iopub.execute_input":"2025-11-27T14:53:02.070705Z","iopub.status.idle":"2025-11-27T14:53:02.106608Z","shell.execute_reply.started":"2025-11-27T14:53:02.070685Z","shell.execute_reply":"2025-11-27T14:53:02.106064Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Train/Validation Split & Single Holdout Evaluation","metadata":{}},{"cell_type":"code","source":"# CHUNK 5: Train/validation split & ROC AUC evaluation\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE,\n)\n\nmodel.fit(X_train, y_train)\n\n# Predict probabilities for positive class\ny_valid_pred = model.predict_proba(X_valid)[:, 1]\n\nvalid_auc = roc_auc_score(y_valid, y_valid_pred)\nprint(f\"Validation ROC AUC: {valid_auc:.5f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:53:02.107228Z","iopub.execute_input":"2025-11-27T14:53:02.107423Z","iopub.status.idle":"2025-11-27T14:54:12.210458Z","shell.execute_reply.started":"2025-11-27T14:53:02.107407Z","shell.execute_reply":"2025-11-27T14:54:12.209685Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Validation ROC AUC: 0.91603\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Cross-Validation","metadata":{}},{"cell_type":"code","source":"# CHUNK 6: Stratified K-Fold cross-validation (optional, for more robust estimate)\n\ncv = StratifiedKFold(\n    n_splits=5,\n    shuffle=True,\n    random_state=RANDOM_STATE\n)\n\ncv_scores = cross_val_score(\n    model,\n    X,\n    y,\n    cv=cv,\n    scoring=\"roc_auc\",\n    n_jobs=-1\n)\n\nprint(\"CV ROC AUC scores:\", cv_scores)\nprint(\"Mean CV ROC AUC:\", cv_scores.mean())\nprint(\"Std CV ROC AUC:\", cv_scores.std())\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:54:12.211184Z","iopub.execute_input":"2025-11-27T14:54:12.211432Z","iopub.status.idle":"2025-11-27T15:00:09.386370Z","shell.execute_reply.started":"2025-11-27T14:54:12.211415Z","shell.execute_reply":"2025-11-27T15:00:09.385724Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CV ROC AUC scores: [0.91784174 0.91695487 0.91554419 0.916699   0.9161969 ]\nMean CV ROC AUC: 0.9166473395878555\nStd CV ROC AUC: 0.0007672921053887465\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CHUNK 6B: Hyperparameter tuning with GridSearchCV (optional, slower but thorough)\n# Uncomment this cell if you want to optimize hyperparameters\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'classifier__learning_rate': [0.005, 0.01, 0.02],\n    'classifier__max_depth': [5, 8, 10],\n    'classifier__max_iter': [300, 500, 700],\n    'classifier__l2_regularization': [0.05, 0.1, 0.2],\n}\n\n# This is computationally expensive - use only if you have time\n# grid_search = GridSearchCV(\n#     model,\n#     param_grid,\n#     cv=cv,\n#     scoring=\"roc_auc\",\n#     n_jobs=-1,\n#     verbose=2\n# )\n# grid_search.fit(X, y)\n# print(\"Best parameters:\", grid_search.best_params_)\n# print(\"Best CV score:\", grid_search.best_score_)\n# model = grid_search.best_estimator_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T15:00:09.387113Z","iopub.execute_input":"2025-11-27T15:00:09.387386Z","iopub.status.idle":"2025-11-27T15:00:09.392003Z","shell.execute_reply.started":"2025-11-27T15:00:09.387358Z","shell.execute_reply":"2025-11-27T15:00:09.391309Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Train on Full Training Data","metadata":{}},{"cell_type":"code","source":"# =========================\n# MODEL + ENSEMBLE SETUP\n# =========================\n\nUSE_ENSEMBLE = False   # Change to True when you actually build an ensemble\n\n# 1. Define preprocessing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nnum_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\nif \"id\" in num_cols:\n    num_cols.remove(\"id\")\n\nnumeric_transformer = SimpleImputer(strategy=\"median\")\ncategorical_transformer = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer([\n    (\"num\", numeric_transformer, num_cols),\n    (\"cat\", categorical_transformer, cat_cols),\n])\n\n# 2. Define base model pipeline\nbase_pipeline = Pipeline([\n    (\"preprocess\", preprocessor),\n    (\"model\", HistGradientBoostingClassifier(\n        learning_rate=0.05,\n        max_iter=300,\n        random_state=42\n    ))\n])\n\n# 3. Define ensemble placeholder (only if USE_ENSEMBLE = True)\n# For now we point ensemble â†’ base_pipeline\nmodel = base_pipeline\nensemble = base_pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T15:09:48.186607Z","iopub.execute_input":"2025-11-27T15:09:48.186894Z","iopub.status.idle":"2025-11-27T15:09:48.319749Z","shell.execute_reply.started":"2025-11-27T15:09:48.186874Z","shell.execute_reply":"2025-11-27T15:09:48.319119Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# CHUNK 7: Fit model on full training data\n\nif USE_ENSEMBLE:\n    ensemble.fit(X, y)\n    print(\"Ensemble model fitted on full training data.\")\n    final_model = ensemble\nelse:\n    model.fit(X, y)\n    print(\"HistGradientBoosting model fitted on full training data.\")\n    final_model = model\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T15:09:52.518009Z","iopub.execute_input":"2025-11-27T15:09:52.518354Z","iopub.status.idle":"2025-11-27T15:10:26.983183Z","shell.execute_reply.started":"2025-11-27T15:09:52.518331Z","shell.execute_reply":"2025-11-27T15:10:26.982538Z"},"trusted":true},"outputs":[{"name":"stdout","text":"HistGradientBoosting model fitted on full training data.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Predict on Test Set & Create Submission","metadata":{}},{"cell_type":"code","source":"# CHUNK 8: Predict test probabilities & create submission file\n\ntest_preds = model.predict_proba(X_test)[:, 1]\n\nsubmission = sample_submission.copy()\nsubmission[\"loan_paid_back\"] = test_preds\n\noutput_path = \"submission.csv\"\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved as: {output_path}\")\ndisplay(submission.head())\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T15:15:00.792996Z","iopub.execute_input":"2025-11-27T15:15:00.793686Z","iopub.status.idle":"2025-11-27T15:15:05.964366Z","shell.execute_reply.started":"2025-11-27T15:15:00.793662Z","shell.execute_reply":"2025-11-27T15:15:05.963761Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Submission file saved as: submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       id  loan_paid_back\n0  593994        0.913990\n1  593995        0.982110\n2  593996        0.449031\n3  593997        0.927829\n4  593998        0.957150","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_paid_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>593994</td>\n      <td>0.913990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>593995</td>\n      <td>0.982110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>593996</td>\n      <td>0.449031</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>593997</td>\n      <td>0.927829</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>593998</td>\n      <td>0.957150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# CHUNK 8A: Ensemble with XGBoost and LightGBM (optional, improves robustness)\n\ntry:\n    import xgboost as xgb\n    import lightgbm as lgb\n    from sklearn.ensemble import VotingClassifier\n    \n    # Create ensemble of different models\n    xgb_model = Pipeline([\n        (\"preprocessor\", preprocessor),\n        (\"classifier\", xgb.XGBClassifier(\n            n_estimators=500,\n            max_depth=6,\n            learning_rate=0.01,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            random_state=RANDOM_STATE,\n            eval_metric='logloss',\n            verbosity=0\n        ))\n    ])\n    \n    lgb_model = Pipeline([\n        (\"preprocessor\", ColumnTransformer(\n            transformers=[\n                (\"num\", numeric_transformer, numeric_features),\n                (\"cat\", categorical_transformer, categorical_features),\n            ]\n        )),\n        (\"classifier\", lgb.LGBMClassifier(\n            n_estimators=500,\n            max_depth=8,\n            learning_rate=0.01,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            random_state=RANDOM_STATE,\n            verbosity=-1\n        ))\n    ])\n    \n    # Ensemble voting\n    ensemble = VotingClassifier(\n        estimators=[\n            ('hgb', model),\n            ('xgb', xgb_model),\n            ('lgb', lgb_model)\n        ],\n        voting='soft',\n        n_jobs=-1\n    )\n    \n    print(\"Ensemble created with HistGradientBoosting, XGBoost, and LightGBM\")\n    USE_ENSEMBLE = True\n    \nexcept ImportError as e:\n    print(f\"XGBoost or LightGBM not available: {e}\")\n    print(\"Will use HistGradientBoosting alone\")\n    USE_ENSEMBLE = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T15:15:13.723908Z","iopub.execute_input":"2025-11-27T15:15:13.724168Z","iopub.status.idle":"2025-11-27T15:15:18.090013Z","shell.execute_reply.started":"2025-11-27T15:15:13.724151Z","shell.execute_reply":"2025-11-27T15:15:18.089249Z"}},"outputs":[{"name":"stdout","text":"Ensemble created with HistGradientBoosting, XGBoost, and LightGBM\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# CHUNK 8B: Make predictions using final model\n\ntest_preds = final_model.predict_proba(X_test)[:, 1]\n\nsubmission = sample_submission.copy()\nsubmission[\"loan_paid_back\"] = test_preds\n\noutput_path = \"submission.csv\"\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved as: {output_path}\")\ndisplay(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T15:15:23.232055Z","iopub.execute_input":"2025-11-27T15:15:23.232934Z","iopub.status.idle":"2025-11-27T15:15:28.313859Z","shell.execute_reply.started":"2025-11-27T15:15:23.232907Z","shell.execute_reply":"2025-11-27T15:15:28.313094Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as: submission.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       id  loan_paid_back\n0  593994        0.913990\n1  593995        0.982110\n2  593996        0.449031\n3  593997        0.927829\n4  593998        0.957150","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_paid_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>593994</td>\n      <td>0.913990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>593995</td>\n      <td>0.982110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>593996</td>\n      <td>0.449031</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>593997</td>\n      <td>0.927829</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>593998</td>\n      <td>0.957150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Quick Feature Importance (Approximate)","metadata":{}},{"cell_type":"code","source":"# CHUNK 9 (optional): Approximate permutation importance (numeric features only)\n\nfrom sklearn.inspection import permutation_importance\n\n# Use the model already fitted on X_train / y_train from Chunk 5\nresult = permutation_importance(\n    model,\n    X_valid,\n    y_valid,\n    n_repeats=5,\n    random_state=RANDOM_STATE,\n    scoring=\"roc_auc\",\n)\n\n# The feature names after ColumnTransformer are hard to track for OHE,\n# so here we just show importance on the raw columns (approximate view).\nimportances = pd.Series(result.importances_mean, index=X_valid.columns).sort_values(ascending=False)\ndisplay(importances.head(20))\n","metadata":{"execution":{"iopub.status.busy":"2025-11-27T15:15:34.859276Z","iopub.execute_input":"2025-11-27T15:15:34.859949Z","iopub.status.idle":"2025-11-27T15:20:23.203584Z","shell.execute_reply.started":"2025-11-27T15:15:34.859925Z","shell.execute_reply":"2025-11-27T15:20:23.202890Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"employment_status                       0.193889\ncredit_score                            0.050509\ndebt_to_income_ratio                    0.042210\ndebt_to_income_ratio_x_interest_rate    0.006616\nloan_amount                             0.001593\nannual_income                           0.001513\ngrade_subgrade                          0.000895\ninterest_rate                           0.000648\ncredit_score_x_interest_rate            0.000631\neducation_level                         0.000522\nannual_income_x_credit_score            0.000484\nannual_income_x_loan_amount             0.000483\nannual_income_x_interest_rate           0.000447\nloan_purpose                            0.000380\nloan_amount_x_interest_rate             0.000378\ndebt_to_income_ratio_x_loan_amount      0.000324\nannual_income_x_debt_to_income_ratio    0.000309\ndebt_to_income_ratio_x_credit_score     0.000298\ncredit_score_x_loan_amount              0.000209\ngender                                  0.000160\ndtype: float64"},"metadata":{}}],"execution_count":17}]}