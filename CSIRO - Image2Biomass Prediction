{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CHUNK 1: Imports, config, and seeding\n\nimport os\nimport random\nimport math\nimport time\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\nfrom sklearn.model_selection import train_test_split\n\n# -------------------------------------------------------------------\n# Reproducibility\n# -------------------------------------------------------------------\ndef seed_everything(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\n\n# -------------------------------------------------------------------\n# Global config\n# -------------------------------------------------------------------\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n\nDATA_DIR = \"/kaggle/input/csiro-biomass\"  # competition dataset root\n\nBATCH_SIZE = 32\nIMG_SIZE = 224\nEPOCHS = 10\nNUM_WORKERS = 2   # you can try 4 if you want\n\n# Target order & weights as per competition description\nTARGET_NAMES = [\n    \"Dry_Green_g\",\n    \"Dry_Dead_g\",\n    \"Dry_Clover_g\",\n    \"GDM_g\",\n    \"Dry_Total_g\",\n]\n\nTARGET_WEIGHTS = {\n    \"Dry_Green_g\": 0.1,\n    \"Dry_Dead_g\": 0.1,\n    \"Dry_Clover_g\": 0.1,\n    \"GDM_g\": 0.2,\n    \"Dry_Total_g\": 0.5,\n}\n\nTARGET_WEIGHTS_ARRAY = np.array([TARGET_WEIGHTS[t] for t in TARGET_NAMES], dtype=np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:42:07.818345Z","iopub.execute_input":"2025-11-21T15:42:07.818800Z","iopub.status.idle":"2025-11-21T15:42:11.474819Z","shell.execute_reply.started":"2025-11-21T15:42:07.818768Z","shell.execute_reply":"2025-11-21T15:42:11.474012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUNK 2: Load train.csv, pivot to wide format (one row per image)\n\ntrain_csv_path = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(train_csv_path)\nprint(\"train.csv shape:\", train_df.shape)\ndisplay(train_df.head())\n\n# Pivot from long format (one row per image/target_name) to wide (one row per image, 5 target columns)\ntargets_wide = train_df.pivot_table(\n    index=\"image_path\",\n    columns=\"target_name\",\n    values=\"target\"\n)\n\n# Ensure consistent target column order and drop any rows missing targets\ntargets_wide = targets_wide[TARGET_NAMES].dropna()\nprint(\"Wide targets shape (images x 5 targets):\", targets_wide.shape)\ndisplay(targets_wide.head())\n\n# Create train/validation split on image_path\nall_image_paths = targets_wide.index.to_list()\ntrain_paths, val_paths = train_test_split(\n    all_image_paths,\n    test_size=0.2,\n    random_state=42\n)\n\nprint(f\"Num train images: {len(train_paths)}, num val images: {len(val_paths)}\")\n\n# Build DataFrames with image_path + target columns\ntrain_targets = targets_wide.loc[train_paths].reset_index().rename(columns={\"image_path\": \"image_path\"})\nval_targets   = targets_wide.loc[val_paths].reset_index().rename(columns={\"image_path\": \"image_path\"})\n\nprint(\"Train targets df:\", train_targets.shape)\nprint(\"Val targets df:\", val_targets.shape)\ndisplay(train_targets.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:42:11.476122Z","iopub.execute_input":"2025-11-21T15:42:11.476449Z","iopub.status.idle":"2025-11-21T15:42:11.524371Z","shell.execute_reply.started":"2025-11-21T15:42:11.476431Z","shell.execute_reply":"2025-11-21T15:42:11.523760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUNK 3: Dataset, transforms & DataLoaders\n\n# Image transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],  # standard ImageNet mean\n        std=[0.229, 0.224, 0.225],   # standard ImageNet std\n    ),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    ),\n])\n\n\nclass CSIROBiomassDataset(Dataset):\n    \"\"\"\n    Dataset for CSIRO Image2Biomass.\n\n    For training/validation: returns (image_tensor, targets_tensor).\n    For test/inference: returns (image_tensor, image_path).\n    \"\"\"\n    def __init__(self, df: pd.DataFrame, root_dir: str, transforms=None, has_targets: bool = True):\n        self.root_dir = root_dir\n        self.transforms = transforms\n        self.has_targets = has_targets\n\n        self.image_paths = df[\"image_path\"].values\n        self.targets = None\n        if has_targets:\n            self.targets = df[TARGET_NAMES].values.astype(np.float32)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        rel_path = self.image_paths[idx]\n        img_path = os.path.join(self.root_dir, rel_path)\n\n        # Read image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transforms is not None:\n            image = self.transforms(image)\n\n        if self.has_targets:\n            target = torch.from_numpy(self.targets[idx])\n            return image, target\n        else:\n            return image, rel_path  # return path so we can map predictions later\n\n\n# Build train/val datasets\ntrain_dataset = CSIROBiomassDataset(\n    df=train_targets,\n    root_dir=DATA_DIR,\n    transforms=train_transform,\n    has_targets=True,\n)\n\nval_dataset = CSIROBiomassDataset(\n    df=val_targets,\n    root_dir=DATA_DIR,\n    transforms=val_transform,\n    has_targets=True,\n)\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nlen(train_loader), len(val_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:42:11.525046Z","iopub.execute_input":"2025-11-21T15:42:11.525233Z","iopub.status.idle":"2025-11-21T15:42:11.538699Z","shell.execute_reply.started":"2025-11-21T15:42:11.525218Z","shell.execute_reply":"2025-11-21T15:42:11.537938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUNK 4: Model definition – ResNet18 multi-target regressor (no external download)\n\nclass ResNetMultiTargetRegressor(nn.Module):\n    def __init__(self, num_targets: int = 5):\n        super().__init__()\n\n        # IMPORTANT: do NOT try to download pretrained weights (no internet in scoring)\n        # Use weights=None so it initializes randomly but runs safely everywhere.\n        self.backbone = models.resnet18(weights=None)\n\n        # Replace final FC layer with identity to get feature vector\n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n\n        # Regression head\n        self.head = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_targets),\n        )\n\n    def forward(self, x):\n        features = self.backbone(x)   # [batch, in_features]\n        out = self.head(features)     # [batch, num_targets]\n        return out\n\n\nmodel = ResNetMultiTargetRegressor(num_targets=len(TARGET_NAMES)).to(DEVICE)\nprint(model)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Weighted MSE loss aligned to competition row weights\nTARGET_WEIGHTS_TORCH = torch.tensor(TARGET_WEIGHTS_ARRAY, device=DEVICE).view(1, -1)\n\ndef weighted_mse_loss(preds: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    preds, targets: shape [batch_size, num_targets]\n    Applies per-target weights then averages.\n    \"\"\"\n    diff = preds - targets\n    loss = (diff * diff) * TARGET_WEIGHTS_TORCH  # broadcast weights over batch\n    return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:42:11.539653Z","iopub.execute_input":"2025-11-21T15:42:11.539949Z","iopub.status.idle":"2025-11-21T15:42:11.862066Z","shell.execute_reply.started":"2025-11-21T15:42:11.539923Z","shell.execute_reply":"2025-11-21T15:42:11.861414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUNK 5: Training loop + weighted R^2 validation metric\n\ndef compute_weighted_r2(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"\n    Approximate competition metric on validation set.\n    Weighted R² using the competition's per-target weights.\n    \"\"\"\n    assert y_true.shape == y_pred.shape\n    n, t = y_true.shape\n    assert t == len(TARGET_NAMES)\n\n    # Flatten\n    y_true_flat = y_true.reshape(-1)\n    y_pred_flat = y_pred.reshape(-1)\n\n    # Expand weights for each observation\n    weights_flat = np.tile(TARGET_WEIGHTS_ARRAY, n)\n\n    w_sum = np.sum(weights_flat)\n    if w_sum == 0:\n        return 0.0\n\n    # Weighted mean\n    y_mean = np.sum(weights_flat * y_true_flat) / w_sum\n\n    rss = np.sum(weights_flat * (y_true_flat - y_pred_flat) ** 2)\n    tss = np.sum(weights_flat * (y_true_flat - y_mean) ** 2)\n\n    if tss == 0:\n        return 0.0\n\n    return 1.0 - rss / tss\n\n\ndef train_one_epoch(model, loader, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    num_batches = 0\n\n    for images, targets in loader:\n        images = images.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n        preds = model(images)\n        loss = weighted_mse_loss(preds, targets)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        num_batches += 1\n\n    return running_loss / max(1, num_batches)\n\n\ndef validate(model, loader, device):\n    model.eval()\n    running_loss = 0.0\n    num_batches = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device)\n            targets = targets.to(device)\n\n            preds = model(images)\n            loss = weighted_mse_loss(preds, targets)\n\n            running_loss += loss.item()\n            num_batches += 1\n\n            all_preds.append(preds.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n\n    val_loss = running_loss / max(1, num_batches)\n\n    if len(all_preds) > 0:\n        y_pred = np.concatenate(all_preds, axis=0)\n        y_true = np.concatenate(all_targets, axis=0)\n        val_r2 = compute_weighted_r2(y_true, y_pred)\n    else:\n        val_r2 = 0.0\n\n    return val_loss, val_r2\n\n\nbest_val_r2 = -1e9\nbest_state_dict = None\n\nfor epoch in range(1, EPOCHS + 1):\n    start_time = time.time()\n\n    train_loss = train_one_epoch(model, train_loader, optimizer, DEVICE)\n    val_loss, val_r2 = validate(model, val_loader, DEVICE)\n\n    elapsed = time.time() - start_time\n    print(\n        f\"Epoch {epoch:02d} | \"\n        f\"train_loss = {train_loss:.4f} | \"\n        f\"val_loss = {val_loss:.4f} | \"\n        f\"val_weighted_R2 = {val_r2:.4f} | \"\n        f\"time = {elapsed:.1f}s\"\n    )\n\n    # Model selection\n    if val_r2 > best_val_r2:\n        best_val_r2 = val_r2\n        best_state_dict = deepcopy(model.state_dict())\n        print(f\"  -> New best model (val_weighted_R2 = {best_val_r2:.4f})\")\n\n\n# Load best weights\nif best_state_dict is not None:\n    model.load_state_dict(best_state_dict)\n    print(\"Loaded best model weights with val_weighted_R2 =\", best_val_r2)\nelse:\n    print(\"WARNING: No best_state_dict found — using last epoch weights.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:42:11.863524Z","iopub.execute_input":"2025-11-21T15:42:11.863763Z","iopub.status.idle":"2025-11-21T15:44:05.795925Z","shell.execute_reply.started":"2025-11-21T15:42:11.863744Z","shell.execute_reply":"2025-11-21T15:44:05.795154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUNK 6: Test inference & submission.csv creation\n\n# Load test.csv\ntest_csv_path = os.path.join(DATA_DIR, \"test.csv\")\ntest_df = pd.read_csv(test_csv_path)\nprint(\"test.csv shape:\", test_df.shape)\ndisplay(test_df.head())\n\n# We want one forward pass per unique image_path\nunique_test_paths = test_df[\"image_path\"].unique()\nprint(\"Unique test images:\", len(unique_test_paths))\n\ntest_images_df = pd.DataFrame({\"image_path\": unique_test_paths})\n\n# Test dataset & loader (no targets)\ntest_dataset = CSIROBiomassDataset(\n    df=test_images_df,\n    root_dir=DATA_DIR,\n    transforms=val_transform,\n    has_targets=False,\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\n# Run inference\nmodel.eval()\nimage_path_to_preds = {}\n\nwith torch.no_grad():\n    for images, paths in test_loader:\n        images = images.to(DEVICE)\n        outputs = model(images)        # [batch, 5]\n        outputs = outputs.cpu().numpy()\n\n        for p, o in zip(paths, outputs):\n            image_path_to_preds[p] = o  # store vector of 5 predictions\n\n\n# Build submission in long format: one row per (image, target_name)\npred_targets = []\n\nfor idx, row in test_df.iterrows():\n    sample_id = row[\"sample_id\"]\n    image_path = row[\"image_path\"]\n    target_name = row[\"target_name\"]\n\n    # Find index of this target_name in TARGET_NAMES\n    target_idx = TARGET_NAMES.index(target_name)\n\n    preds_for_image = image_path_to_preds[image_path]\n    pred_value = float(preds_for_image[target_idx])\n\n    pred_targets.append(pred_value)\n\nsubmission = pd.DataFrame({\n    \"sample_id\": test_df[\"sample_id\"],\n    \"target\": pred_targets,\n})\n\nprint(\"Submission shape:\", submission.shape)\ndisplay(submission.head(10))\n\n# Save submission.csv in /kaggle/working\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(submission_path, index=False)\nprint(\"Saved submission to:\", submission_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T15:44:05.796795Z","iopub.execute_input":"2025-11-21T15:44:05.797001Z","iopub.status.idle":"2025-11-21T15:44:06.002237Z","shell.execute_reply.started":"2025-11-21T15:44:05.796979Z","shell.execute_reply":"2025-11-21T15:44:06.001534Z"}},"outputs":[],"execution_count":null}]}